---
title: 'Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds Revisited'
abstract: In this paper, we propose new problem-independent lower bounds on the sample
  complexity and regret in episodic MDPs, with a particular focus on the \emph{non-stationary
  case} in which the transition kernel is allowed to change in each stage of the episode.
  Our main contribution is a lower bound of $\Omega((H^3SA/\epsilon^2)\log(1/\delta))$
  on the sample complexity of an $(\varepsilon,\delta)$-PAC algorithm for best policy
  identification in a non-stationary MDP, relying on a construction of “hard MDPs”
  which is different from the ones previously used in the literature. Using this same
  class of MDPs, we also provide a rigorous proof of the $\Omega(\sqrt{H^3SAT})$ regret
  bound for non-stationary MDPs. Finally, we discuss connections to PAC-MDP lower
  bounds.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: domingues21a
month: 0
tex_title: 'Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds Revisited'
firstpage: 578
lastpage: 598
page: 578-598
order: 578
cycles: false
bibtex_author: Domingues, Omar Darwiche and M{\'e}nard, Pierre and Kaufmann, Emilie
  and Valko, Michal
author:
- given: Omar Darwiche
  family: Domingues
- given: Pierre
  family: Ménard
- given: Emilie
  family: Kaufmann
- given: Michal
  family: Valko
date: 2021-03-01
address: 
container-title: Proceedings of the 32nd International Conference on Algorithmic Learning
  Theory
volume: '132'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 1
pdf: http://proceedings.mlr.press/v132/domingues21a/domingues21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

---
title: 'Stable Sample Compression Schemes: New Applications and an Optimal SVM Margin
  Bound'
abstract: We analyze a family of supervised learning algorithms based on sample compression
  schemes that are stable, in the sense that removing points from the training set
  which were not selected for the compression set does not alter the resulting classifier.
  We use this technique to derive a variety of novel or improved data-dependent generalization
  bounds for several learning algorithms. In particular, we prove a new margin bound
  for SVM, removing a log factor. The new bound is provably optimal. This resolves
  a long-standing open question about the PAC margin bounds achievable by SVM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hanneke21a
month: 0
tex_title: 'Stable Sample Compression Schemes: New Applications and an Optimal {SVM}
  Margin Bound'
firstpage: 697
lastpage: 721
page: 697-721
order: 697
cycles: false
bibtex_author: Hanneke, Steve and Kontorovich, Aryeh
author:
- given: Steve
  family: Hanneke
- given: Aryeh
  family: Kontorovich
date: 2021-03-01
address: 
container-title: Proceedings of the 32nd International Conference on Algorithmic Learning
  Theory
volume: '132'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 1
pdf: http://proceedings.mlr.press/v132/hanneke21a/hanneke21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

---
title: Self-Tuning Bandits over Unknown Covariate-Shifts
abstract: Bandits with covariates, a.k.a. \emph{contextual bandits}, address situations
  where optimal actions (or arms) at a given time $t$, depend on a \emph{context}
  $x_t$, e.g., a new patient’s medical history, a consumer’s past purchases. While
  it is understood that the distribution of contexts might change over time, e.g.,
  due to seasonalities, or deployment to new environments, the bulk of studies concern
  the most adversarial such changes, resulting in regret bounds that are often worst-case
  in nature. \emph{Covariate-shift} on the other hand has been considered in classification
  as a middle-ground formalism that can capture mild to relatively severe changes
  in distributions. We consider nonparametric bandits under such middle-ground scenarios,
  and derive new regret bounds that tightly capture a continuum of changes in context
  distribution. Furthermore, we show that these rates can be \emph{adaptively} attained
  without knowledge of the time of shift (change point) nor the amount of shift.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: suk21a
month: 0
tex_title: Self-Tuning Bandits over Unknown Covariate-Shifts
firstpage: 1114
lastpage: 1156
page: 1114-1156
order: 1114
cycles: false
bibtex_author: Suk, Joseph and Kpotufe, Samory
author:
- given: Joseph
  family: Suk
- given: Samory
  family: Kpotufe
date: 2021-03-01
address: 
container-title: Proceedings of the 32nd International Conference on Algorithmic Learning
  Theory
volume: '132'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 1
pdf: http://proceedings.mlr.press/v132/suk21a/suk21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
